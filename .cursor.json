{
  "version": 1,
  "formatOnSave": true,
  "formatOnPaste": true,
  "formatOnType": false,
  "defaultFormatter": "black",
  "formatters": {
    "black": {
      "command": "black",
      "args": ["--line-length", "88", "${file}"]
    },
    "isort": {
      "command": "isort",
      "args": ["--profile", "black", "${file}"]
    }
  },
  "linters": {
    "ruff": {
      "command": "ruff",
      "args": ["check", "${file}"],
      "rootPatterns": ["pyproject.toml"]
    },
    "mypy": {
      "command": "mypy",
      "args": ["${file}"],
      "rootPatterns": ["pyproject.toml"]
    }
  },
  "runOnSave": {
    "**/*.py": ["black", "isort", "ruff"]
  },
  "fileWatcher": {
    "patterns": ["**/*.py", "**/*.yaml", "**/*.toml", "**/*.html"],
    "ignore": ["**/__pycache__/**", "**/.venv/**", "**/venv/**", "**/.git/**"]
  },
  "snippets": {
    "python": {
      "ray-remote": {
        "prefix": "rayremote",
        "body": [
          "@ray.remote",
          "def ${1:function_name}(${2:parameters}):",
          "    \"\"\"${3:Function description}\"\"\"",
          "    ${0:pass}"
        ],
        "description": "Create a Ray remote function"
      },
      "crewai-flow-with-output-format": {
        "prefix": "crewaiflow",
        "body": [
          "class ${1:FlowName}State(BaseModel):",
          "    \"\"\"Define your flow state here.\"\"\"",
          "    output_format: str = \"markdown\"  # Default output format (markdown or json)",
          "    ${2:other_parameters}: ${3:type} = ${4:default_value}",
          "",
          "    @property",
          "    def is_valid_output_format(self) -> bool:",
          "        \"\"\"Check if the output format is valid.\"\"\"",
          "        return self.output_format.lower() in [\"markdown\", \"json\"]",
          "",
          "class ${1:FlowName}(Flow[${1:FlowName}State]):",
          "    \"\"\"Define your flow steps here.\"\"\"",
          "",
          "    @start()",
          "    def validate_inputs(self):",
          "        \"\"\"Validate the inputs to the flow.\"\"\"",
          "        # Validate output format",
          "        if not self.state.is_valid_output_format:",
          "            print(f\"Invalid output format: {self.state.output_format}. Using default (markdown).\")",
          "            self.state.output_format = \"markdown\"",
          "        ${0:pass}",
          "",
          "    def _format_as_markdown(self, data: Dict[str, Any]) -> str:",
          "        \"\"\"Format the data as a markdown string.\"\"\"",
          "        # Build the markdown output",
          "        md = [",
          "            f\"# ${5:Title}\",",
          "            \"\",",
          "            \"## ${6:Section}\",",
          "            \"\"",
          "        ]",
          "        return \"\\n\".join(md)"
        ],
        "description": "Create a CrewAI Flow with output format support"
      },
      "ray-remote-class": {
        "prefix": "rayremoteclass",
        "body": [
          "@ray.remote",
          "class ${1:ClassName}:",
          "    \"\"\"${2:Class description}\"\"\"",
          "    ",
          "    def __init__(self, ${3:parameters}):",
          "        ${4:pass}",
          "    ",
          "    def ${5:method_name}(self, ${6:parameters}):",
          "        ${0:pass}"
        ],
        "description": "Create a Ray remote class"
      },
      "crewai-agent": {
        "prefix": "crewaiagent",
        "body": [
          "agent = Agent(",
          "    name=\"${1:Agent Name}\",",
          "    role=\"${2:Agent Role}\",",
          "    goal=\"${3:Agent Goal}\",",
          "    backstory=\"${4:Agent Backstory}\",",
          "    llm=self.llm,",
          "    verbose=${5:True}",
          ")"
        ],
        "description": "Create a CrewAI Agent"
      },
      "crewai-task": {
        "prefix": "crewaitask",
        "body": [
          "task = Task(",
          "    name=\"${1:Task Name}\",",
          "    agent=${2:agent},",
          "    description=\"${3:Task Description}\",",
          "    expected_output=\"${4:Expected Output}\"",
          ")"
        ],
        "description": "Create a CrewAI Task"
      },
      "kodosumi-deploy": {
        "prefix": "kodosumiapp",
        "body": [
          "from pathlib import Path",
          "",
          "from fastapi import Request",
          "from fastapi.responses import HTMLResponse",
          "from fastapi.templating import Jinja2Templates",
          "from ray.serve import deployment, ingress",
          "",
          "from kodosumi.serve import Launch, ServeAPI",
          "",
          "",
          "app = ServeAPI()  # Use ServeAPI instead of FastAPI",
          "",
          "templates = Jinja2Templates(",
          "    directory=Path(__file__).parent.joinpath(\"templates\"))",
          "",
          "@deployment",
          "@ingress(app)",
          "class ${1:ServiceName}:",
          "    \"\"\"${2:Service description}\"\"\"",
          "    ",
          "    @app.get(\"/\", ",
          "             name=\"${3:Display Name}\", ",
          "             description=\"${4:Service description for UI}\")",
          "    async def get(self, request: Request) -> HTMLResponse:",
          "        \"\"\"Handle GET requests.\"\"\"",
          "        return templates.TemplateResponse(",
          "            request=request, ",
          "            name=\"${5:template.html}\", ",
          "            context={})",
          "    ",
          "    @app.post(\"/\", response_model=None)",
          "    async def post(self, request: Request):",
          "        \"\"\"Handle POST requests.\"\"\"",
          "        form_data = await request.form()",
          "        ${6:param_name} = str(form_data.get(\"${6:param_name}\", \"\"))",
          "        ",
          "        # Extract output format if needed",
          "        output_format = str(form_data.get(\"output_format\", \"markdown\"))",
          "        ",
          "        # Launch the flow using the Kodosumi Launch function",
          "        return Launch(request, \"${7:module.path:function}\", {",
          "            \"${6:param_name}\": ${6:param_name},",
          "            \"output_format\": output_format",
          "        })",
          "",
          "# Bind the service to Ray Serve",
          "fast_app = ${1:ServiceName}.bind()"
        ],
        "description": "Create a Kodosumi service with ServeAPI"
      },
      "output-format-handler": {
        "prefix": "outputformat",
        "body": [
          "# Extract output format from the form",
          "output_format = str(form_data.get(\"output_format\", \"markdown\"))",
          "",
          "# Validate output format",
          "if output_format not in [\"markdown\", \"json\"]:",
          "    output_format = \"markdown\"  # Default to markdown if invalid",
          "",
          "# Include output_format in the parameters",
          "return Launch(request, \"${1:module.path:function}\", {",
          "    \"${2:other_param}\": form_data.get(\"${2:other_param}\", \"\"),",
          "    \"output_format\": output_format",
          "})"
        ],
        "description": "Handle output format in a Kodosumi service"
      },
      "kodosumi-local-test": {
        "prefix": "kodomsumitest",
        "body": [
          "# Kodosumi Deployment Commands",
          "",
          "# 1. Start a local Ray cluster (if not already running)",
          "# ray start --head",
          "# ray status  # Check if Ray is running properly",
          "",
          "# 2. Start Kodosumi spooler",
          "# python -m kodosumi.cli spool",
          "",
          "# 3. Create/update Ray Serve configuration in config.yaml",
          "# - name: ${1:app_name}",
          "# - route_prefix: /${2:route_prefix}",
          "# - import_path: workflows.${3:module_path}.serve:fast_app",
          "# - runtime_env:",
          "#     env_vars:",
          "#       OPENAI_API_KEY: your_api_key_here",
          "#       EXA_API_KEY: your_api_key_here",
          "#       OTEL_SDK_DISABLED: \"true\"",
          "#     pip:",
          "#     - crewai==0.86.*",
          "#     - crewai_tools==0.17.*",
          "",
          "# 4. Deploy with Ray Serve",
          "# serve deploy ./config.yaml",
          "",
          "# 5. Start Kodosumi services",
          "# python -m kodosumi.cli serve --register http://localhost:8001/-/routes",
          "",
          "# 6. Access the service at http://localhost:3370",
          "",
          "# 7. Test with curl commands (if needed)",
          "# Test markdown output (default):",
          "# curl -X POST \"http://localhost:8001/${2:route_prefix}/\" -d \"dataset_name=${4:dataset_name}\"",
          "",
          "# Test JSON output (for agent-to-agent):",
          "# curl -X POST \"http://localhost:8001/${2:route_prefix}/\" -d \"dataset_name=${4:dataset_name}&output_format=json\""
        ],
        "description": "Commands for deploying and testing with Kodosumi"
      },
      "ray-cluster-init": {
        "prefix": "rayinit",
        "body": [
          "import ray",
          "",
          "# Initialize Ray or connect to existing cluster",
          "if not ray.is_initialized():",
          "    ray_address = os.environ.get(\"RAY_ADDRESS\")",
          "    if ray_address:",
          "        ray.init(address=ray_address)",
          "    else:",
          "        ray.init()",
          "    print(f\"Ray initialized: {ray.cluster_resources()}\")"
        ],
        "description": "Initialize Ray or connect to existing cluster"
      },
      "local-testing-main": {
        "prefix": "localtestmain",
        "body": [
          "if __name__ == \"__main__\":",
          "    \"\"\"",
          "    Main entry point for local testing.",
          "    Run this script directly to test the flow with a local Ray cluster.",
          "    ",
          "    First start a local Ray cluster with: ray start --head",
          "    Then run this script: python -m workflows.${1:module_path}.main",
          "    \"\"\"",
          "    import asyncio",
          "    import sys",
          "    import time",
          "    import json",
          "",
          "    # Parse command line arguments",
          "    args = {}",
          "    for arg in sys.argv[1:]:",
          "        if \"=\" in arg:",
          "            key, value = arg.split(\"=\", 1)",
          "            args[key] = value",
          "",
          "    # Set default arguments if not provided",
          "    if \"dataset_name\" not in args:",
          "        args[\"dataset_name\"] = \"${2:default_dataset}\"",
          "    if \"output_format\" not in args:",
          "        args[\"output_format\"] = \"markdown\"  # Default for human readability",
          "",
          "    print(f\"Running local test with arguments: {args}\")",
          "    start_time = time.time()",
          "",
          "    # Run the flow",
          "    result = asyncio.run(kickoff(args))",
          "",
          "    # Print the result",
          "    print(f\"\\nFlow execution completed in {time.time() - start_time:.2f} seconds.\")",
          "    ",
          "    if args.get(\"output_format\") == \"json\":",
          "        # For JSON output, pretty print it",
          "        print(json.dumps(result, indent=2))",
          "    else:",
          "        # For markdown output, print as is",
          "        print(result)",
          "    ",
          "    # Shutdown Ray if we initialized it",
          "    if ray.is_initialized():",
          "        print(\"Shutting down Ray...\")",
          "        ray.shutdown()",
          "        print(\"Ray shutdown complete.\")"
        ],
        "description": "Create a main block for local testing with Ray"
      },
      "exa-web-search": {
        "prefix": "exasearch",
        "body": [
          "from langchain_community.tools.exa.exa_search import ExaSearchTool",
          "",
          "# Create an Exa search tool",
          "exa_search = ExaSearchTool(",
          "    api_key=os.environ.get(\"EXA_API_KEY\"),",
          "    max_results=${1:5}",
          ")",
          "",
          "# Add the tool to your agent",
          "agent = Agent(",
          "    name=\"${2:Research Agent}\",",
          "    role=\"${3:Web Researcher}\",",
          "    goal=\"${4:Find accurate information from the web}\",",
          "    backstory=\"${5:I am a web research specialist}\",",
          "    tools=[exa_search],",
          "    llm=self.llm,",
          "    verbose=True",
          ")"
        ],
        "description": "Create an Exa.ai web search tool for CrewAI"
      },
      "ray-serve-config": {
        "prefix": "rayserveconfig",
        "body": [
          "# config.yaml for Ray Serve deployment",
          "",
          "proxy_location: EveryNode",
          "http_options:",
          "  host: 127.0.0.1",
          "  port: 8001",
          "grpc_options:",
          "  port: 9001",
          "  grpc_servicer_functions: []",
          "logging_config:",
          "  encoding: TEXT",
          "  log_level: DEBUG",
          "  logs_dir: null",
          "  enable_access_log: true",
          "applications:",
          "- name: ${1:app_name}",
          "  route_prefix: /${2:route_prefix}",
          "  import_path: workflows.${3:module_path}.serve:fast_app",
          "  runtime_env:",
          "    env_vars:",
          "      PYTHONPATH: .",
          "      OPENAI_API_KEY: ${4:your_openai_api_key}",
          "      EXA_API_KEY: ${5:your_exa_api_key}",
          "      OTEL_SDK_DISABLED: \"true\"",
          "    pip:",
          "    - crewai==0.86.*",
          "    - crewai_tools==0.17.*"
        ],
        "description": "Create a Ray Serve config.yaml file for Kodosumi deployment"
      }
    }
  },
  "pathMappings": {
    "workflows": "${workspaceFolder}/workflows"
  }
} 